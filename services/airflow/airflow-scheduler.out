[[34m2024-07-19T01:31:16.053+0300[0m] {[34mscheduler_job_runner.py:[0m797} INFO[0m - Starting the scheduler[0m
[[34m2024-07-19T01:31:16.054+0300[0m] {[34mscheduler_job_runner.py:[0m804} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-07-19T01:31:16.235+0300[0m] {[34mmanager.py:[0m166} INFO[0m - Launched DagFileProcessorManager with pid: 8160[0m
[[34m2024-07-19T01:31:16.237+0300[0m] {[34mscheduler_job_runner.py:[0m1605} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-19T01:31:16.261+0300[0m] {[34msettings.py:[0m61} INFO[0m - Configured default timezone Timezone('UTC')[0m
[[34m2024-07-19T01:32:45.067+0300[0m] {[34mdag.py:[0m3722} INFO[0m - Setting next_dagrun for extract_data to 2024-07-18T22:30:00+00:00, run_after=2024-07-18T22:40:00+00:00[0m
[[34m2024-07-19T01:32:45.204+0300[0m] {[34mscheduler_job_runner.py:[0m413} INFO[0m - 2 tasks up for execution:
	<TaskInstance: extract_data.sample_data_task scheduled__2024-07-18T22:20:00+00:00 [scheduled]>
	<TaskInstance: extract_data.sample_data_task manual__2024-07-18T22:32:44.684558+00:00 [scheduled]>[0m
[[34m2024-07-19T01:32:45.206+0300[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG extract_data has 0/16 running and queued tasks[0m
[[34m2024-07-19T01:32:45.214+0300[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG extract_data has 1/16 running and queued tasks[0m
[[34m2024-07-19T01:32:45.218+0300[0m] {[34mscheduler_job_runner.py:[0m592} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: extract_data.sample_data_task scheduled__2024-07-18T22:20:00+00:00 [scheduled]>
	<TaskInstance: extract_data.sample_data_task manual__2024-07-18T22:32:44.684558+00:00 [scheduled]>[0m
[[34m2024-07-19T01:32:45.227+0300[0m] {[34mtaskinstance.py:[0m1441} WARNING[0m - cannot record scheduled_duration for task sample_data_task because previous state change time has not been saved[0m
[[34m2024-07-19T01:32:45.229+0300[0m] {[34mtaskinstance.py:[0m1441} WARNING[0m - cannot record scheduled_duration for task sample_data_task because previous state change time has not been saved[0m
[[34m2024-07-19T01:32:45.231+0300[0m] {[34mscheduler_job_runner.py:[0m635} INFO[0m - Sending TaskInstanceKey(dag_id='extract_data', task_id='sample_data_task', run_id='scheduled__2024-07-18T22:20:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-19T01:32:45.235+0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'extract_data', 'sample_data_task', 'scheduled__2024-07-18T22:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/data_extract_dag.py'][0m
[[34m2024-07-19T01:32:45.240+0300[0m] {[34mscheduler_job_runner.py:[0m635} INFO[0m - Sending TaskInstanceKey(dag_id='extract_data', task_id='sample_data_task', run_id='manual__2024-07-18T22:32:44.684558+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-19T01:32:45.242+0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'extract_data', 'sample_data_task', 'manual__2024-07-18T22:32:44.684558+00:00', '--local', '--subdir', 'DAGS_FOLDER/data_extract_dag.py'][0m
[[34m2024-07-19T01:32:45.249+0300[0m] {[34mlocal_executor.py:[0m89} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'extract_data', 'sample_data_task', 'scheduled__2024-07-18T22:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/data_extract_dag.py'][0m
[[34m2024-07-19T01:32:45.249+0300[0m] {[34mlocal_executor.py:[0m89} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'extract_data', 'sample_data_task', 'manual__2024-07-18T22:32:44.684558+00:00', '--local', '--subdir', 'DAGS_FOLDER/data_extract_dag.py'][0m
[[34m2024-07-19T01:32:45.390+0300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py[0m
[[34m2024-07-19T01:32:45.391+0300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py[0m
[[34m2024-07-19T01:33:01.255+0300[0m] {[34mwarnings.py:[0m109} WARNING[0m - /mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py:20: RemovedInAirflow3Warning: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead. 
  with DAG(**dag_args) as dag:
[0m
[[34m2024-07-19T01:33:01.256+0300[0m] {[34mwarnings.py:[0m109} WARNING[0m - /mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py:20: RemovedInAirflow3Warning: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead. 
  with DAG(**dag_args) as dag:
[0m
[33m/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py:20: RemovedInAirflow3Warning: Param [0m[1;36mschedule_interval[33m is deprecated and will be removed in a future release. Please use [0m[1;36mschedule[33m instead. 
  with DAG(**dag_args) as dag:
[0m
[33m/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py:20: RemovedInAirflow3Warning: Param [0m[1;36mschedule_interval[33m is deprecated and will be removed in a future release. Please use [0m[1;36mschedule[33m instead. 
  with DAG(**dag_args) as dag:
[0m
[[34m2024-07-19T01:33:01.270+0300[0m] {[34mtemplater.py:[0m76} ERROR[0m - Failed to resolve template field 'bash_command'[0m
Traceback (most recent call last):
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 74, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: cd /mnt/c/Users/danil/Desktop/try_2/MLOps && ./scripts/versioning_sample.sh[0m
[[34m2024-07-19T01:33:01.270+0300[0m] {[34mtemplater.py:[0m76} ERROR[0m - Failed to resolve template field 'bash_command'[0m
Traceback (most recent call last):
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 74, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: cd /mnt/c/Users/danil/Desktop/try_2/MLOps && ./scripts/versioning_sample.sh[0m
[31mFailed to resolve template field 'bash_command'[0m
Traceback (most recent call last):
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 74, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: cd /mnt/c/Users/danil/Desktop/try_2/MLOps && ./scripts/versioning_sample.sh
[31mFailed to resolve template field 'bash_command'[0m
Traceback (most recent call last):
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 74, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: cd /mnt/c/Users/danil/Desktop/try_2/MLOps && ./scripts/versioning_sample.sh
Changing /home/tanel/MLOps/services/airflow/logs/dag_id=extract_data/run_id=manual__2024-07-18T22:32:44.684558+00:00/task_id=sample_data_task permission to 509
[[34m2024-07-19T01:33:01.383+0300[0m] {[34mtask_command.py:[0m416} INFO[0m - Running <TaskInstance: extract_data.sample_data_task manual__2024-07-18T22:32:44.684558+00:00 [queued]> on host DESKTOP-JMQGBI7.[0m
Changing /home/tanel/MLOps/services/airflow/logs/dag_id=extract_data/run_id=scheduled__2024-07-18T22:20:00+00:00/task_id=sample_data_task permission to 509
[1;35mRunning <TaskInstance: extract_data.sample_data_task manual__2024-07-18T22:32:44.684558+00:00 [queued]> on host DESKTOP-JMQGBI7.[0m
[[34m2024-07-19T01:33:01.384+0300[0m] {[34mtask_command.py:[0m416} INFO[0m - Running <TaskInstance: extract_data.sample_data_task scheduled__2024-07-18T22:20:00+00:00 [queued]> on host DESKTOP-JMQGBI7.[0m
[1;35mRunning <TaskInstance: extract_data.sample_data_task scheduled__2024-07-18T22:20:00+00:00 [queued]> on host DESKTOP-JMQGBI7.[0m
[[34m2024-07-19T01:33:01.960+0300[0m] {[34mscheduler_job_runner.py:[0m685} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_data', task_id='sample_data_task', run_id='scheduled__2024-07-18T22:20:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-19T01:33:01.967+0300[0m] {[34mscheduler_job_runner.py:[0m722} INFO[0m - TaskInstance Finished: dag_id=extract_data, task_id=sample_data_task, run_id=scheduled__2024-07-18T22:20:00+00:00, map_index=-1, run_start_date=2024-07-18 22:33:01.639799+00:00, run_end_date=None, run_duration=None, state=running, executor_state=success, try_number=1, max_tries=0, job_id=6, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 22:32:45.224112+00:00, queued_by_job_id=5, pid=8269[0m
[[34m2024-07-19T01:33:03.017+0300[0m] {[34mscheduler_job_runner.py:[0m685} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_data', task_id='sample_data_task', run_id='manual__2024-07-18T22:32:44.684558+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-19T01:33:03.022+0300[0m] {[34mscheduler_job_runner.py:[0m722} INFO[0m - TaskInstance Finished: dag_id=extract_data, task_id=sample_data_task, run_id=manual__2024-07-18T22:32:44.684558+00:00, map_index=-1, run_start_date=2024-07-18 22:33:01.639742+00:00, run_end_date=None, run_duration=None, state=running, executor_state=success, try_number=1, max_tries=0, job_id=7, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 22:32:45.224112+00:00, queued_by_job_id=5, pid=8270[0m
[[34m2024-07-19T01:33:07.348+0300[0m] {[34mscheduler_job_runner.py:[0m1736} WARNING[0m - Failing (2) jobs without heartbeat after 2024-07-18 22:28:07.344146+00:00[0m
[[34m2024-07-19T01:33:07.348+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'manual__2024-07-18T22:32:44.684558+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20be9bdf0>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:07.350+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'scheduled__2024-07-18T22:20:00+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bd1ae30>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:17.454+0300[0m] {[34mscheduler_job_runner.py:[0m1736} WARNING[0m - Failing (2) jobs without heartbeat after 2024-07-18 22:28:17.450090+00:00[0m
[[34m2024-07-19T01:33:17.455+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'manual__2024-07-18T22:32:44.684558+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bc1bb50>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:17.456+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'scheduled__2024-07-18T22:20:00+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bc11c30>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:27.562+0300[0m] {[34mscheduler_job_runner.py:[0m1736} WARNING[0m - Failing (2) jobs without heartbeat after 2024-07-18 22:28:27.559244+00:00[0m
[[34m2024-07-19T01:33:27.563+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'scheduled__2024-07-18T22:20:00+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20f67fb80>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:27.564+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'manual__2024-07-18T22:32:44.684558+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bbe75b0>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:37.656+0300[0m] {[34mscheduler_job_runner.py:[0m1736} WARNING[0m - Failing (2) jobs without heartbeat after 2024-07-18 22:28:37.651592+00:00[0m
[[34m2024-07-19T01:33:37.657+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'scheduled__2024-07-18T22:20:00+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20be15fc0>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:37.658+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'manual__2024-07-18T22:32:44.684558+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bc453f0>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:47.757+0300[0m] {[34mscheduler_job_runner.py:[0m1736} WARNING[0m - Failing (2) jobs without heartbeat after 2024-07-18 22:28:47.753609+00:00[0m
[[34m2024-07-19T01:33:47.758+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'scheduled__2024-07-18T22:20:00+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bc8e2c0>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:47.759+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'manual__2024-07-18T22:32:44.684558+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bbc27a0>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:57.833+0300[0m] {[34mscheduler_job_runner.py:[0m1736} WARNING[0m - Failing (2) jobs without heartbeat after 2024-07-18 22:28:57.829298+00:00[0m
[[34m2024-07-19T01:33:57.834+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'scheduled__2024-07-18T22:20:00+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bc8e2c0>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:33:57.835+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'manual__2024-07-18T22:32:44.684558+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bc11300>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:34:00.078+0300[0m] {[34mdagrun.py:[0m632} ERROR[0m - Marking run <DagRun extract_data @ 2024-07-18 22:20:00+00:00: scheduled__2024-07-18T22:20:00+00:00, state:running, queued_at: 2024-07-18 22:32:45.031530+00:00. externally triggered: False> failed[0m
[[34m2024-07-19T01:34:00.079+0300[0m] {[34mdagrun.py:[0m704} INFO[0m - DagRun Finished: dag_id=extract_data, execution_date=2024-07-18 22:20:00+00:00, run_id=scheduled__2024-07-18T22:20:00+00:00, run_start_date=2024-07-18 22:32:45.095547+00:00, run_end_date=2024-07-18 22:34:00.079756+00:00, run_duration=74.984209, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-18 22:20:00+00:00, data_interval_end=2024-07-18 22:30:00+00:00, dag_hash=d69cff78333d8ecd8769dd03757812fb[0m
[[34m2024-07-19T01:34:00.085+0300[0m] {[34mdag.py:[0m3722} INFO[0m - Setting next_dagrun for extract_data to 2024-07-18T22:30:00+00:00, run_after=2024-07-18T22:40:00+00:00[0m
[[34m2024-07-19T01:34:00.092+0300[0m] {[34mdagrun.py:[0m632} ERROR[0m - Marking run <DagRun extract_data @ 2024-07-18 22:32:44.684558+00:00: manual__2024-07-18T22:32:44.684558+00:00, state:running, queued_at: 2024-07-18 22:32:44.726620+00:00. externally triggered: True> failed[0m
[[34m2024-07-19T01:34:00.093+0300[0m] {[34mdagrun.py:[0m704} INFO[0m - DagRun Finished: dag_id=extract_data, execution_date=2024-07-18 22:32:44.684558+00:00, run_id=manual__2024-07-18T22:32:44.684558+00:00, run_start_date=2024-07-18 22:32:45.095981+00:00, run_end_date=2024-07-18 22:34:00.093858+00:00, run_duration=74.997877, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-07-18 22:20:00+00:00, data_interval_end=2024-07-18 22:30:00+00:00, dag_hash=d69cff78333d8ecd8769dd03757812fb[0m
[[34m2024-07-19T01:36:16.523+0300[0m] {[34mscheduler_job_runner.py:[0m1605} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-19T01:40:00.408+0300[0m] {[34mdag.py:[0m3722} INFO[0m - Setting next_dagrun for extract_data to 2024-07-18T22:40:00+00:00, run_after=2024-07-18T22:50:00+00:00[0m
[[34m2024-07-19T01:40:00.460+0300[0m] {[34mscheduler_job_runner.py:[0m413} INFO[0m - 1 tasks up for execution:
	<TaskInstance: extract_data.sample_data_task scheduled__2024-07-18T22:30:00+00:00 [scheduled]>[0m
[[34m2024-07-19T01:40:00.461+0300[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG extract_data has 0/16 running and queued tasks[0m
[[34m2024-07-19T01:40:00.462+0300[0m] {[34mscheduler_job_runner.py:[0m592} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: extract_data.sample_data_task scheduled__2024-07-18T22:30:00+00:00 [scheduled]>[0m
[[34m2024-07-19T01:40:00.464+0300[0m] {[34mtaskinstance.py:[0m1441} WARNING[0m - cannot record scheduled_duration for task sample_data_task because previous state change time has not been saved[0m
[[34m2024-07-19T01:40:00.466+0300[0m] {[34mscheduler_job_runner.py:[0m635} INFO[0m - Sending TaskInstanceKey(dag_id='extract_data', task_id='sample_data_task', run_id='scheduled__2024-07-18T22:30:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-19T01:40:00.467+0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'extract_data', 'sample_data_task', 'scheduled__2024-07-18T22:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/data_extract_dag.py'][0m
[[34m2024-07-19T01:40:00.475+0300[0m] {[34mlocal_executor.py:[0m89} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'extract_data', 'sample_data_task', 'scheduled__2024-07-18T22:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/data_extract_dag.py'][0m
[[34m2024-07-19T01:40:00.552+0300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py[0m
[[34m2024-07-19T01:40:22.047+0300[0m] {[34mwarnings.py:[0m109} WARNING[0m - /mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py:20: RemovedInAirflow3Warning: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead. 
  with DAG(**dag_args) as dag:
[0m
[33m/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py:20: RemovedInAirflow3Warning: Param [0m[1;36mschedule_interval[33m is deprecated and will be removed in a future release. Please use [0m[1;36mschedule[33m instead. 
  with DAG(**dag_args) as dag:
[0m
[[34m2024-07-19T01:40:22.064+0300[0m] {[34mtemplater.py:[0m76} ERROR[0m - Failed to resolve template field 'bash_command'[0m
Traceback (most recent call last):
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 74, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: cd /mnt/c/Users/danil/Desktop/try_2/MLOps && ./scripts/versioning_sample.sh[0m
[31mFailed to resolve template field 'bash_command'[0m
Traceback (most recent call last):
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 74, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: cd /mnt/c/Users/danil/Desktop/try_2/MLOps && ./scripts/versioning_sample.sh
Changing /home/tanel/MLOps/services/airflow/logs/dag_id=extract_data/run_id=scheduled__2024-07-18T22:30:00+00:00/task_id=sample_data_task permission to 509
[[34m2024-07-19T01:40:22.231+0300[0m] {[34mtask_command.py:[0m416} INFO[0m - Running <TaskInstance: extract_data.sample_data_task scheduled__2024-07-18T22:30:00+00:00 [queued]> on host DESKTOP-JMQGBI7.[0m
[1;35mRunning <TaskInstance: extract_data.sample_data_task scheduled__2024-07-18T22:30:00+00:00 [queued]> on host DESKTOP-JMQGBI7.[0m
[[34m2024-07-19T01:40:22.822+0300[0m] {[34mscheduler_job_runner.py:[0m685} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_data', task_id='sample_data_task', run_id='scheduled__2024-07-18T22:30:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-19T01:40:22.827+0300[0m] {[34mscheduler_job_runner.py:[0m722} INFO[0m - TaskInstance Finished: dag_id=extract_data, task_id=sample_data_task, run_id=scheduled__2024-07-18T22:30:00+00:00, map_index=-1, run_start_date=2024-07-18 22:40:22.459165+00:00, run_end_date=None, run_duration=None, state=running, executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 22:40:00.463189+00:00, queued_by_job_id=5, pid=8584[0m
[[34m2024-07-19T01:40:30.755+0300[0m] {[34mscheduler_job_runner.py:[0m1736} WARNING[0m - Failing (1) jobs without heartbeat after 2024-07-18 22:35:30.751761+00:00[0m
[[34m2024-07-19T01:40:30.756+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'scheduled__2024-07-18T22:30:00+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bae0220>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:40:40.843+0300[0m] {[34mscheduler_job_runner.py:[0m1736} WARNING[0m - Failing (1) jobs without heartbeat after 2024-07-18 22:35:40.839745+00:00[0m
[[34m2024-07-19T01:40:40.844+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'scheduled__2024-07-18T22:30:00+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20baeee00>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:40:50.925+0300[0m] {[34mscheduler_job_runner.py:[0m1736} WARNING[0m - Failing (1) jobs without heartbeat after 2024-07-18 22:35:50.921661+00:00[0m
[[34m2024-07-19T01:40:50.926+0300[0m] {[34mscheduler_job_runner.py:[0m1746} ERROR[0m - Detected zombie job: {'full_filepath': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags/data_extract_dag.py', 'processor_subdir': '/mnt/c/Users/danil/Desktop/try_2/MLOps/services/airflow/dags', 'msg': "{'DAG Id': 'extract_data', 'Task Id': 'sample_data_task', 'Run Id': 'scheduled__2024-07-18T22:30:00+00:00', 'Hostname': 'DESKTOP-JMQGBI7.'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fb20bd189a0>, 'is_failure_callback': True}[0m
[[34m2024-07-19T01:40:54.128+0300[0m] {[34mdagrun.py:[0m632} ERROR[0m - Marking run <DagRun extract_data @ 2024-07-18 22:30:00+00:00: scheduled__2024-07-18T22:30:00+00:00, state:running, queued_at: 2024-07-18 22:40:00.397991+00:00. externally triggered: False> failed[0m
[[34m2024-07-19T01:40:54.129+0300[0m] {[34mdagrun.py:[0m704} INFO[0m - DagRun Finished: dag_id=extract_data, execution_date=2024-07-18 22:30:00+00:00, run_id=scheduled__2024-07-18T22:30:00+00:00, run_start_date=2024-07-18 22:40:00.422501+00:00, run_end_date=2024-07-18 22:40:54.129220+00:00, run_duration=53.706719, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-18 22:30:00+00:00, data_interval_end=2024-07-18 22:40:00+00:00, dag_hash=d69cff78333d8ecd8769dd03757812fb[0m
[[34m2024-07-19T01:40:54.135+0300[0m] {[34mdag.py:[0m3722} INFO[0m - Setting next_dagrun for extract_data to 2024-07-18T22:40:00+00:00, run_after=2024-07-18T22:50:00+00:00[0m
[[34m2024-07-19T01:41:16.580+0300[0m] {[34mscheduler_job_runner.py:[0m1605} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-19T01:42:22.069+0300[0m] {[34mscheduler_job_runner.py:[0m247} INFO[0m - Exiting gracefully upon receiving signal 15[0m
[[34m2024-07-19T01:42:23.099+0300[0m] {[34mprocess_utils.py:[0m131} INFO[0m - Sending Signals.SIGTERM to group 8160. PIDs of all processes in the group: [8643, 8160][0m
[[34m2024-07-19T01:42:23.102+0300[0m] {[34mprocess_utils.py:[0m86} INFO[0m - Sending the signal Signals.SIGTERM to group 8160[0m
[2024-07-19T01:42:37.681+0300] {process_utils.py:256} INFO - Terminating child PID: 8643
[2024-07-19T01:42:37.681+0300] {process_utils.py:259} INFO - Waiting up to 5 seconds for processes to exit...
[2024-07-19T01:42:39.599+0300] {process_utils.py:262} INFO - Terminated PID 8643
[[34m2024-07-19T01:42:39.614+0300[0m] {[34mprocess_utils.py:[0m79} INFO[0m - Process psutil.Process(pid=8160, status='terminated', exitcode=0, started='01:31:16') (8160) terminated with exit code 0[0m
[[34m2024-07-19T01:42:39.616+0300[0m] {[34mprocess_utils.py:[0m79} INFO[0m - Process psutil.Process(pid=8643, status='terminated', started='01:42:14') (8643) terminated with exit code None[0m
[[34m2024-07-19T01:42:39.617+0300[0m] {[34mlocal_executor.py:[0m402} INFO[0m - Shutting down LocalExecutor; waiting for running tasks to finish.  Signal again if you don't want to wait.[0m
[[34m2024-07-19T01:42:39.618+0300[0m] {[34mscheduler_job_runner.py:[0m867} ERROR[0m - Exception when executing Executor.end[0m
Traceback (most recent call last):
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 844, in _execute
    self._run_scheduler_loop()
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 999, in _run_scheduler_loop
    time.sleep(min(self._scheduler_idle_sleep_time, next_event if next_event else 0))
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 250, in _exit_gracefully
    sys.exit(os.EX_OK)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 865, in _execute
    self.job.executor.end()
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/executors/local_executor.py", line 406, in end
    self.impl.end()
  File "/mnt/c/Users/danil/Desktop/try_2/MLOps/venv/lib/python3.10/site-packages/airflow/executors/local_executor.py", line 350, in end
    self.queue.put((None, None))
  File "<string>", line 2, in put
  File "/usr/lib/python3.10/multiprocessing/managers.py", line 817, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe[0m
[[34m2024-07-19T01:42:39.642+0300[0m] {[34mprocess_utils.py:[0m131} INFO[0m - Sending Signals.SIGTERM to group 8160. PIDs of all processes in the group: [][0m
[[34m2024-07-19T01:42:39.643+0300[0m] {[34mprocess_utils.py:[0m86} INFO[0m - Sending the signal Signals.SIGTERM to group 8160[0m
[[34m2024-07-19T01:42:39.644+0300[0m] {[34mprocess_utils.py:[0m100} INFO[0m - Sending the signal Signals.SIGTERM to process 8160 as process group is missing.[0m
[[34m2024-07-19T01:42:39.646+0300[0m] {[34mscheduler_job_runner.py:[0m873} INFO[0m - Exited execute loop[0m
